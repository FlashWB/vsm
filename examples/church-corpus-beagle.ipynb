{
 "metadata": {
  "name": "",
  "signature": "sha256:83cdba9a7ba78681d94c4f9847bb3bd5835754b45fbbe9cab1d7c65725562023"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from vsm import *\n",
      "from vsm.ext.corpusbuilders import toy_corpus\n",
      "\n",
      "\n",
      "plain_corpus = \"\"\"\n",
      "His theology challenged the Pope of the Roman Catholic Church by\n",
      "teaching that the Bible is the only source of divinely revealed\n",
      "knowledge.\n",
      "\n",
      "Augustine is held in the Catholic Church to be the model teacher.\n",
      "\n",
      "Augustine was recognized as a Doctor of the Church by Pope Boniface\n",
      "VIII.\n",
      "\n",
      "Roman Catholic theology stated that faith alone cannot justify man.\n",
      "\n",
      "In the Catholic Church the Pope is regarded as the successor of Saint\n",
      "Peter.\n",
      "\n",
      "Alonzo Church was an American mathematician and logician who made\n",
      "major contributions to mathematical logic and the foundations of\n",
      "theoretical computer science.\n",
      "\n",
      "The lambda calculus was introduced by mathematician Alonzo Church as\n",
      "an investigation into the foundations of mathematics.\n",
      "\n",
      "The Church Turing thesis states that a function is algorithmically\n",
      "computable if and only if it is computable by a Turing machine.\n",
      "\n",
      "Mathematical logic has close connections to the foundations of\n",
      "mathematics, theoretical computer science.\n",
      "\n",
      "A Turing machine can be adapted to simulate the logic of any computer\n",
      "algorithm.\n",
      "\"\"\"\n",
      "\n",
      "metadata = ['Ecclesiastical ' + str(i) for i in xrange(1, 6)]\n",
      "\n",
      "metadata += ['Logic ' + str(i) for i in xrange(1, 6)]\n",
      "\n",
      "env_c = toy_corpus(plain_corpus, nltk_stop=False, metadata=metadata)\n",
      "c = toy_corpus(plain_corpus, nltk_stop=True, metadata=metadata)\n",
      "\n",
      "e = BeagleEnvironment(env_c, context_type='document')\n",
      "e.train()\n",
      "\n",
      "m = BeagleContextSeq(c, env_c, e.matrix, context_type='document')\n",
      "m.train()\n",
      "\n",
      "v = BeagleViewer(c, m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Stop list is empty.\n",
        "Removing stop words\n",
        "Rebuilding corpus\n",
        "Recomputing token breaks: document\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v.dist_word_word('logic', print_len=24)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table style=\"margin: 0\"><tr><th style=\"text-align: center; background: #CEE3F6\" colspan                    =\"4\">Words: logic</th></tr><tr><th style=\"text-align: center; background: #EFF2FB; \">Word                    </th><th style=\"text-align: center; background: #EFF2FB; \">Distance                    </th><th style=\"text-align: center; background: #EFF2FB; \">Word                    </th><th style=\"text-align: center; background: #EFF2FB; \">Distance                    </th></tr><tr><td>logic               </td><td>0.00000   </td><td>close               </td><td>0.75215   </td></tr><tr><td>theoretical         </td><td>0.60283   </td><td>mathematician       </td><td>0.79846   </td></tr><tr><td>science             </td><td>0.61200   </td><td>alonzo              </td><td>0.80991   </td></tr><tr><td>mathematical        </td><td>0.61391   </td><td>mathematics         </td><td>0.83140   </td></tr><tr><td>computer            </td><td>0.66420   </td><td>church              </td><td>1.09886   </td></tr><tr><td>logician            </td><td>0.66775   </td><td>simulate            </td><td>1.10878   </td></tr><tr><td>american            </td><td>0.67298   </td><td>algorithm           </td><td>1.11603   </td></tr><tr><td>major               </td><td>0.67602   </td><td>adapted             </td><td>1.11772   </td></tr><tr><td>made                </td><td>0.67742   </td><td>introduced          </td><td>1.20677   </td></tr><tr><td>contributions       </td><td>0.67902   </td><td>lambda              </td><td>1.21564   </td></tr><tr><td>foundations         </td><td>0.71510   </td><td>calculus            </td><td>1.21937   </td></tr><tr><td>connections         </td><td>0.74351   </td><td>investigation       </td><td>1.23257   </td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "LabeledColumn([('logic', 0.0), ('theoretical', 0.6028309231139475),\n",
        "       ('science', 0.6120043765113564),\n",
        "       ('mathematical', 0.6139076673306048),\n",
        "       ('computer', 0.6642005504036089), ('logician', 0.6677512894550222),\n",
        "       ('american', 0.6729764625269348), ('major', 0.676017641279689),\n",
        "       ('made', 0.6774154017564942), ('contributions', 0.6790182561154686),\n",
        "       ('foundations', 0.7150998116822241),\n",
        "       ('connections', 0.7435108875360489), ('close', 0.7521535359504922),\n",
        "       ('mathematician', 0.7984554374258538),\n",
        "       ('alonzo', 0.8099056941186431), ('mathematics', 0.8313981270976704),\n",
        "       ('church', 1.0988587786799529), ('simulate', 1.108775890179098),\n",
        "       ('algorithm', 1.116030502475676), ('adapted', 1.1177169552237889),\n",
        "       ('introduced', 1.206765478604353), ('lambda', 1.2156447926845826),\n",
        "       ('calculus', 1.2193740382076217),\n",
        "       ('investigation', 1.2325720878738586),\n",
        "       ('machine', 1.2512684100622957), ('turing', 1.280686641860385),\n",
        "       ('states', 1.375474128670607), ('computable', 1.3755799935095752),\n",
        "       ('function', 1.380675607096211),\n",
        "       ('algorithmically', 1.3937106208238033),\n",
        "       ('thesis', 1.3961500935813227), ('augustine', 1.4587404335588876),\n",
        "       ('teacher', 1.4619940035746817), ('pope', 1.4751653272974172),\n",
        "       ('viii', 1.478224681258278), ('doctor', 1.479646897741685),\n",
        "       ('saint', 1.483256342012972), ('regarded', 1.484033568142339),\n",
        "       ('recognized', 1.4865306646835972), ('model', 1.4867178936211407),\n",
        "       ('peter', 1.4916836104130335), ('catholic', 1.4920555526214578),\n",
        "       ('successor', 1.4923911668450494), ('held', 1.4963931039289593),\n",
        "       ('boniface', 1.5044711837416007), ('source', 1.517789313517826),\n",
        "       ('challenged', 1.5185652981722355),\n",
        "       ('divinely', 1.5226376051446795), ('bible', 1.5309749252857539),\n",
        "       ('knowledge', 1.5324558269274917), ('revealed', 1.5332572712174357),\n",
        "       ('teaching', 1.5349173822800715), ('theology', 1.5420273809633314),\n",
        "       ('roman', 1.5481194033224968), ('alone', 1.579282143223117),\n",
        "       ('man', 1.579563972785118), ('justify', 1.580578157434103),\n",
        "       ('stated', 1.5813227379513448), ('faith', 1.5870265504154097)], \n",
        "      dtype=[('word', 'S15'), ('value', '<f8')])"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.around(v.dismat_word(['logic','church','catholic','pope']), decimals=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "array([[ 0.  ,  1.1 ,  1.49,  1.48],\n",
        "       [ 1.1 ,  0.  ,  1.13,  1.05],\n",
        "       [ 1.49,  1.13,  0.  ,  0.81],\n",
        "       [ 1.48,  1.05,  0.81,  0.  ]])"
       ]
      }
     ],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}